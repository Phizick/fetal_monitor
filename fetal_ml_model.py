#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
–ú–æ–¥–µ–ª—å –º–∞—à–∏–Ω–Ω–æ–≥–æ –æ–±—É—á–µ–Ω–∏—è –¥–ª—è –ø—Ä–µ–¥–∏–∫—Ç–∏–≤–Ω–æ–π –∞–Ω–∞–ª–∏—Ç–∏–∫–∏ —Ñ–µ—Ç–∞–ª—å–Ω–æ–≥–æ –º–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥–∞
–û–±—É—á–∞–µ—Ç –º–æ–¥–µ–ª—å, —Å–æ–∑–¥–∞–µ—Ç —Ç–µ—Å—Ç–æ–≤—É—é –≤—ã–±–æ—Ä–∫—É –∏ –ø—Ä–æ–≤–µ—Ä—è–µ—Ç —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã
"""

import pandas as pd
import numpy as np
from sklearn.model_selection import train_test_split, cross_val_score, StratifiedKFold
from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier
from sklearn.linear_model import LogisticRegression
from sklearn.svm import SVC
from sklearn.metrics import classification_report, confusion_matrix, accuracy_score, roc_auc_score
from sklearn.preprocessing import StandardScaler, LabelEncoder
from sklearn.impute import SimpleImputer
from sklearn.pipeline import Pipeline
import joblib
import warnings
warnings.filterwarnings('ignore')

# –í–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏—è –Ω–µ –∏—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è –≤ —Ä–∞–±–æ—á–µ–π –≤–µ—Ä—Å–∏–∏ –º–æ–¥–µ–ª–∏

class FetalMLPredictor:
    """
    –ö–ª–∞—Å—Å –¥–ª—è –ø–æ—Å—Ç—Ä–æ–µ–Ω–∏—è –∏ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è –º–æ–¥–µ–ª–∏ –º–∞—à–∏–Ω–Ω–æ–≥–æ –æ–±—É—á–µ–Ω–∏—è
    –¥–ª—è –ø—Ä–µ–¥–∏–∫—Ç–∏–≤–Ω–æ–π –∞–Ω–∞–ª–∏—Ç–∏–∫–∏ —Ñ–µ—Ç–∞–ª—å–Ω–æ–≥–æ –º–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥–∞
    """
    
    def __init__(self, csv_file):
        """
        –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –ø—Ä–µ–¥–∏–∫—Ç–æ—Ä–∞
        Args:
            csv_file (str): –ø—É—Ç—å –∫ CSV —Ñ–∞–π–ª—É —Å –¥–∞–Ω–Ω—ã–º–∏
        """
        self.csv_file = csv_file
        self.data = None
        self.X = None
        self.y = None
        self.X_train = None
        self.X_test = None
        self.y_train = None
        self.y_test = None
        self.models = {}
        self.best_model = None
        # –ü–∞–π–ø–ª–∞–π–Ω –±—É–¥–µ—Ç –≤–∫–ª—é—á–∞—Ç—å –∏–º–ø—É—Ç–∞—Ü–∏—é/—Å–∫–µ–π–ª–∏–Ω–≥ –ø—Ä–∏ –Ω–µ–æ–±—Ö–æ–¥–∏–º–æ—Å—Ç–∏
        self.scaler = None
        self.label_encoder = LabelEncoder()
        self.feature_names = None
        self.model_performance = {}
        
    def load_and_prepare_data(self):
        """
        –ó–∞–≥—Ä—É–∂–∞–µ—Ç –¥–∞–Ω–Ω—ã–µ –∏ –ø–æ–¥–≥–æ—Ç–∞–≤–ª–∏–≤–∞–µ—Ç –∏—Ö –¥–ª—è –º–∞—à–∏–Ω–Ω–æ–≥–æ –æ–±—É—á–µ–Ω–∏—è
        """
        print("–ó–∞–≥—Ä—É–∑–∫–∞ –∏ –ø–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –¥–∞–Ω–Ω—ã—Ö –¥–ª—è –º–∞—à–∏–Ω–Ω–æ–≥–æ –æ–±—É—á–µ–Ω–∏—è...")
        
        # –ó–∞–≥—Ä—É–∂–∞–µ–º –¥–∞–Ω–Ω—ã–µ
        self.data = pd.read_csv(self.csv_file)
        print(f"–î–∞–Ω–Ω—ã–µ –∑–∞–≥—Ä—É–∂–µ–Ω—ã: {self.data.shape[0]} –∑–∞–ø–∏—Å–µ–π, {self.data.shape[1]} –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤")
        
        # –°–æ–∑–¥–∞–µ–º —Ü–µ–ª–µ–≤—É—é –ø–µ—Ä–µ–º–µ–Ω–Ω—É—é –Ω–∞ –æ—Å–Ω–æ–≤–µ fetal_health
        # 1 = Normal, 2 = Suspect, 3 = Pathological
        self.y = self.data['fetal_health'].copy()
        
        # –ü–æ–¥–≥–æ—Ç–∞–≤–ª–∏–≤–∞–µ–º –ø—Ä–∏–∑–Ω–∞–∫–∏ (–∏—Å–∫–ª—é—á–∞–µ–º —Ü–µ–ª–µ–≤—É—é –ø–µ—Ä–µ–º–µ–Ω–Ω—É—é)
        feature_columns = [col for col in self.data.columns if col != 'fetal_health']
        self.X = self.data[feature_columns].copy()
        self.feature_names = feature_columns
        
        print(f"–ü—Ä–∏–∑–Ω–∞–∫–∏: {len(feature_columns)}")
        print(f"–¶–µ–ª–µ–≤–∞—è –ø–µ—Ä–µ–º–µ–Ω–Ω–∞—è: {self.y.value_counts().to_dict()}")
        
        # –ù–µ –∑–∞–ø–æ–ª–Ω—è–µ–º –∑–¥–µ—Å—å ‚Äî –∏–º–ø—É—Ç–∞—Ü–∏—è –±—É–¥–µ—Ç –≤–Ω—É—Ç—Ä–∏ Pipeline
        mv = self.X.isnull().sum()
        if mv.any():
            print("–û–±–Ω–∞—Ä—É–∂–µ–Ω—ã –ø—Ä–æ–ø—É—Å–∫–∏, –±—É–¥—É—Ç –∑–∞–ø–æ–ª–Ω–µ–Ω—ã –º–µ–¥–∏–∞–Ω–∞–º–∏ –≤ Pipeline")
        else:
            print("–ü—Ä–æ–ø—É—Å–∫–æ–≤ –Ω–µ –æ–±–Ω–∞—Ä—É–∂–µ–Ω–æ")
        
        return self.X, self.y
    
    def split_data(self, test_size=0.2, random_state=42):
        """
        –†–∞–∑–¥–µ–ª—è–µ—Ç –¥–∞–Ω–Ω—ã–µ –Ω–∞ –æ–±—É—á–∞—é—â—É—é –∏ —Ç–µ—Å—Ç–æ–≤—É—é –≤—ã–±–æ—Ä–∫–∏
        """
        print(f"–†–∞–∑–¥–µ–ª–µ–Ω–∏–µ –¥–∞–Ω–Ω—ã—Ö: {test_size*100}% –¥–ª—è —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è")
        
        self.X_train, self.X_test, self.y_train, self.y_test = train_test_split(
            self.X, self.y, test_size=test_size, random_state=random_state, stratify=self.y
        )
        
        # –°–∫–µ–π–ª–∏–Ω–≥/–∏–º–ø—É—Ç–∞—Ü–∏—è –≤—ã–ø–æ–ª–Ω—è—é—Ç—Å—è –≤ Pipeline –ø–æ –Ω–µ–æ–±—Ö–æ–¥–∏–º–æ—Å—Ç–∏ –∫–æ–Ω–∫—Ä–µ—Ç–Ω–æ–π –º–æ–¥–µ–ª–∏
        
        print(f"–û–±—É—á–∞—é—â–∞—è –≤—ã–±–æ—Ä–∫–∞: {self.X_train.shape[0]} –∑–∞–ø–∏—Å–µ–π")
        print(f"–¢–µ—Å—Ç–æ–≤–∞—è –≤—ã–±–æ—Ä–∫–∞: {self.X_test.shape[0]} –∑–∞–ø–∏—Å–µ–π")
        
        return self.X_train, self.X_test, self.y_train, self.y_test
    
    def train_models(self):
        """
        –û–±—É—á–∞–µ—Ç –Ω–µ—Å–∫–æ–ª—å–∫–æ –º–æ–¥–µ–ª–µ–π –º–∞—à–∏–Ω–Ω–æ–≥–æ –æ–±—É—á–µ–Ω–∏—è
        """
        print("\n–û–±—É—á–µ–Ω–∏–µ –º–æ–¥–µ–ª–µ–π –º–∞—à–∏–Ω–Ω–æ–≥–æ –æ–±—É—á–µ–Ω–∏—è...")
        
        # –û–ø—Ä–µ–¥–µ–ª—è–µ–º –∫–æ–Ω–≤–µ–π–µ—Ä—ã –º–æ–¥–µ–ª–µ–π (—Å –∏–º–ø—É—Ç–∞—Ü–∏–µ–π –∏, –ø—Ä–∏ –Ω–µ–æ–±—Ö–æ–¥–∏–º–æ—Å—Ç–∏, —Å–∫–µ–π–ª–∏–Ω–≥–æ–º)
        models = {
            'Random Forest': Pipeline([
                ('imputer', SimpleImputer(strategy='median')),
                ('clf', RandomForestClassifier(n_estimators=300, random_state=42, class_weight='balanced_subsample')),
            ]),
            'Gradient Boosting': Pipeline([
                ('imputer', SimpleImputer(strategy='median')),
                ('clf', GradientBoostingClassifier(n_estimators=200, random_state=42)),
            ]),
            'Logistic Regression': Pipeline([
                ('imputer', SimpleImputer(strategy='median')),
                ('scaler', StandardScaler(with_mean=True, with_std=True)),
                ('clf', LogisticRegression(random_state=42, max_iter=2000, class_weight='balanced', n_jobs=None)),
            ]),
            'SVM': Pipeline([
                ('imputer', SimpleImputer(strategy='median')),
                ('scaler', StandardScaler(with_mean=True, with_std=True)),
                ('clf', SVC(random_state=42, probability=True, class_weight='balanced')),
            ]),
        }
        
        # –ö—Ä–æ—Å—Å-–≤–∞–ª–∏–¥–∞—Ü–∏—è (Stratified K-Fold) –¥–ª—è –æ—Ü–µ–Ω–∫–∏ –∏ –≤—ã–±–æ—Ä–∞ –ª—É—á—à–µ–π –º–æ–¥–µ–ª–∏
        cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)
        cv_scores = {}
        for name, pipeline in models.items():
            print(f"–û—Ü–µ–Ω–∫–∞ CV {name}...")
            scores = cross_val_score(pipeline, self.X_train, self.y_train, cv=cv, scoring='roc_auc_ovr', n_jobs=None)
            cv_scores[name] = scores.mean()
            print(f"  {name}: CV AUC (mean over 5 folds) = {scores.mean():.4f}")

        # –í—ã–±–æ—Ä –ª—É—á—à–µ–≥–æ –ø–æ —Å—Ä–µ–¥–Ω–µ–º—É CV AUC
        best_model_name = max(cv_scores.keys(), key=lambda x: cv_scores[x])
        best_pipeline = models[best_model_name]
        print(f"\n–õ—É—á—à–∞—è –º–æ–¥–µ–ª—å –ø–æ CV: {best_model_name} (CV AUC = {cv_scores[best_model_name]:.4f})")

        # –û–±—É—á–∞–µ–º –ª—É—á—à—É—é –º–æ–¥–µ–ª—å –Ω–∞ train –∏ –æ—Ü–µ–Ω–∏–≤–∞–µ–º –Ω–∞ test
        best_pipeline.fit(self.X_train, self.y_train)
        y_pred = best_pipeline.predict(self.X_test)
        y_pred_proba = best_pipeline.predict_proba(self.X_test)

        accuracy = accuracy_score(self.y_test, y_pred)
        auc = roc_auc_score(self.y_test, y_pred_proba, multi_class='ovr')

        self.models = {
            best_model_name: {
                'model': best_pipeline,
                'accuracy': accuracy,
                'auc': auc,
                'predictions': y_pred,
                'probabilities': y_pred_proba,
            }
        }
        self.best_model = best_pipeline
        print(f"–¢–µ—Å—Ç–æ–≤—ã–µ –º–µ—Ç—Ä–∏–∫–∏ –ª—É—á—à–µ–π –º–æ–¥–µ–ª–∏: Accuracy = {accuracy:.4f}, AUC = {auc:.4f}")
        
        # –í—ã–±–∏—Ä–∞–µ–º –ª—É—á—à—É—é –º–æ–¥–µ–ª—å –ø–æ AUC
        best_model_name = max(self.models.keys(), key=lambda x: self.models[x]['auc'])
        self.best_model = self.models[best_model_name]['model']
        
        print(f"\n–õ—É—á—à–∞—è –º–æ–¥–µ–ª—å: {best_model_name} (AUC = {self.models[best_model_name]['auc']:.4f})")
        
        return self.models
    
    def evaluate_models(self):
        """
        –î–µ—Ç–∞–ª—å–Ω–æ –æ—Ü–µ–Ω–∏–≤–∞–µ—Ç –∫–∞—á–µ—Å—Ç–≤–æ –º–æ–¥–µ–ª–µ–π
        """
        print("\n–î–µ—Ç–∞–ª—å–Ω–∞—è –æ—Ü–µ–Ω–∫–∞ –∫–∞—á–µ—Å—Ç–≤–∞ –º–æ–¥–µ–ª–µ–π...")
        
        for name, model_info in self.models.items():
            print(f"\n{'='*50}")
            print(f"–ú–û–î–ï–õ–¨: {name}")
            print(f"{'='*50}")

            y_pred = model_info['predictions']
            print(f"–¢–æ—á–Ω–æ—Å—Ç—å: {model_info['accuracy']:.4f}")
            print(f"AUC: {model_info['auc']:.4f}")
            print("\n–û—Ç—á–µ—Ç –ø–æ –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏–∏:")
            print(classification_report(self.y_test, y_pred, target_names=['Normal', 'Suspect', 'Pathological']))

            cm = confusion_matrix(self.y_test, y_pred)
            print(f"\n–ú–∞—Ç—Ä–∏—Ü–∞ –æ—à–∏–±–æ–∫:")
            print(cm)

            self.model_performance[name] = {
                'accuracy': model_info['accuracy'],
                'auc': model_info['auc'],
                'confusion_matrix': cm,
                'classification_report': classification_report(
                    self.y_test, y_pred,
                    target_names=['Normal', 'Suspect', 'Pathological'],
                    output_dict=True,
                ),
            }
    
    def visualize_model_performance(self):
        """–û—Ç–∫–ª—é—á–µ–Ω–æ: –≤–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏—è –Ω–µ –∏—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è –≤ —Ä–∞–±–æ—á–µ–π –≤–µ—Ä—Å–∏–∏."""
        return
    
    def _plot_roc_curves(self):
        return
    
    def _plot_feature_importance(self):
        return
    
    def save_model(self, model_name='best_fetal_model'):
        """
        –°–æ—Ö—Ä–∞–Ω—è–µ—Ç –ª—É—á—à—É—é –º–æ–¥–µ–ª—å –∏ —Å–∫–µ–π–ª–µ—Ä
        """
        print(f"–°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –º–æ–¥–µ–ª–∏: {model_name}")
        
        # –°–æ—Ö—Ä–∞–Ω—è–µ–º pipeline –ª—É—á—à–µ–π –º–æ–¥–µ–ª–∏
        joblib.dump(self.best_model, f'{model_name}.pkl')
        # –°–æ—Ö—Ä–∞–Ω—è–µ–º –∏–º–µ–Ω–∞ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤
        joblib.dump(self.feature_names, f'{model_name}_features.pkl')
        
        print(f"–ú–æ–¥–µ–ª—å —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∞: {model_name}.pkl")
        print(f"–°–∫–µ–π–ª–µ—Ä —Å–æ—Ö—Ä–∞–Ω–µ–Ω: {model_name}_scaler.pkl")
        print(f"–ü—Ä–∏–∑–Ω–∞–∫–∏ —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã: {model_name}_features.pkl")
    
    def load_model(self, model_name='best_fetal_model'):
        """
        –ó–∞–≥—Ä—É–∂–∞–µ—Ç —Å–æ—Ö—Ä–∞–Ω–µ–Ω–Ω—É—é –º–æ–¥–µ–ª—å
        """
        print(f"–ó–∞–≥—Ä—É–∑–∫–∞ –º–æ–¥–µ–ª–∏: {model_name}")
        
        try:
            self.best_model = joblib.load(f'{model_name}.pkl')
            self.feature_names = joblib.load(f'{model_name}_features.pkl')
            print("–ú–æ–¥–µ–ª—å —É—Å–ø–µ—à–Ω–æ –∑–∞–≥—Ä—É–∂–µ–Ω–∞")
        except FileNotFoundError as e:
            print(f"‚ö†Ô∏è  –§–∞–π–ª –º–æ–¥–µ–ª–∏ –Ω–µ –Ω–∞–π–¥–µ–Ω: {e}")
            print("üîÑ –°–æ–∑–¥–∞–Ω–∏–µ –∑–∞–≥–ª—É—à–∫–∏ –º–æ–¥–µ–ª–∏...")
            self._create_dummy_model()
            print("‚úÖ –ó–∞–≥–ª—É—à–∫–∞ –º–æ–¥–µ–ª–∏ —Å–æ–∑–¥–∞–Ω–∞")
        except Exception as e:
            print(f"‚ùå –û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ –º–æ–¥–µ–ª–∏: {e}")
            print("üîÑ –°–æ–∑–¥–∞–Ω–∏–µ –∑–∞–≥–ª—É—à–∫–∏ –º–æ–¥–µ–ª–∏...")
            self._create_dummy_model()
            print("‚úÖ –ó–∞–≥–ª—É—à–∫–∞ –º–æ–¥–µ–ª–∏ —Å–æ–∑–¥–∞–Ω–∞")
    
    def _create_dummy_model(self):
        """
        –°–æ–∑–¥–∞–µ—Ç –∑–∞–≥–ª—É—à–∫—É –º–æ–¥–µ–ª–∏ –¥–ª—è —Ä–∞–±–æ—Ç—ã –±–µ–∑ –æ–±—É—á–µ–Ω–Ω—ã—Ö —Ñ–∞–π–ª–æ–≤
        """
        from sklearn.ensemble import RandomForestClassifier
        import numpy as np
        
        # –°–æ–∑–¥–∞–µ–º –ø—Ä–æ—Å—Ç—É—é –∑–∞–≥–ª—É—à–∫—É
        self.best_model = RandomForestClassifier(n_estimators=10, random_state=42)
        
        # –û–±—É—á–∞–µ–º –Ω–∞ —Ñ–∏–∫—Ç–∏–≤–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö
        X_dummy = np.random.rand(100, 5)
        y_dummy = np.random.randint(0, 3, 100)
        self.best_model.fit(X_dummy, y_dummy)
        
        # –°–æ–∑–¥–∞–µ–º —Ñ–∏–∫—Ç–∏–≤–Ω—ã–µ –∏–º–µ–Ω–∞ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤
        self.feature_names = ['fhr_bpm', 'uc_mmHg', 'baseline_bpm', 'variability_bpm', 'accel']
        
        print("‚ö†Ô∏è  –ò—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è –∑–∞–≥–ª—É—à–∫–∞ –º–æ–¥–µ–ª–∏ - ML —Ñ—É–Ω–∫—Ü–∏–∏ –æ–≥—Ä–∞–Ω–∏—á–µ–Ω—ã")
    
    def predict_single(self, features):
        """
        –ü—Ä–µ–¥—Å–∫–∞–∑—ã–≤–∞–µ—Ç –∫–ª–∞—Å—Å –¥–ª—è –æ–¥–Ω–æ–≥–æ –æ–±—Ä–∞–∑—Ü–∞
        Args:
            features: —Å–ª–æ–≤–∞—Ä—å –∏–ª–∏ –º–∞—Å—Å–∏–≤ —Å –ø—Ä–∏–∑–Ω–∞–∫–∞–º–∏
        Returns:
            dict: –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–µ —Å –≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç—è–º–∏
        """
        if isinstance(features, dict):
            feature_array = np.array([features.get(col, np.nan) for col in self.feature_names]).reshape(1, -1)
        else:
            feature_array = np.array(features).reshape(1, -1)
        prediction = self.best_model.predict(feature_array)[0]
        probabilities = self.best_model.predict_proba(feature_array)[0]
        
        # –ü—Ä–µ–æ–±—Ä–∞–∑—É–µ–º –≤ —á–∏—Ç–∞–µ–º—ã–π —Ñ–æ—Ä–º–∞—Ç
        class_names = {1: 'Normal', 2: 'Suspect', 3: 'Pathological'}
        
        result = {
            'prediction': class_names[prediction],
            'prediction_code': prediction,
            'probabilities': {
                'Normal': probabilities[0],
                'Suspect': probabilities[1], 
                'Pathological': probabilities[2]
            },
            'confidence': max(probabilities)
        }
        
        return result
    
    def predict_batch(self, features_array):
        """
        –ü—Ä–µ–¥—Å–∫–∞–∑—ã–≤–∞–µ—Ç –∫–ª–∞—Å—Å—ã –¥–ª—è –º–Ω–æ–∂–µ—Å—Ç–≤–∞ –æ–±—Ä–∞–∑—Ü–æ–≤
        Args:
            features_array: –º–∞—Å—Å–∏–≤ —Å –ø—Ä–∏–∑–Ω–∞–∫–∞–º–∏ (n_samples, n_features)
        Returns:
            list: —Å–ø–∏—Å–æ–∫ –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–π
        """
        predictions = self.best_model.predict(features_array)
        probabilities = self.best_model.predict_proba(features_array)
        
        # –ü—Ä–µ–æ–±—Ä–∞–∑—É–µ–º –≤ —á–∏—Ç–∞–µ–º—ã–π —Ñ–æ—Ä–º–∞—Ç
        class_names = {1: 'Normal', 2: 'Suspect', 3: 'Pathological'}
        
        results = []
        for pred, prob in zip(predictions, probabilities):
            result = {
                'prediction': class_names[pred],
                'prediction_code': pred,
                'probabilities': {
                    'Normal': prob[0],
                    'Suspect': prob[1],
                    'Pathological': prob[2]
                },
                'confidence': max(prob)
            }
            results.append(result)
        
        return results


def main():
    """
    –û—Å–Ω–æ–≤–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è –¥–ª—è –æ–±—É—á–µ–Ω–∏—è –∏ —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è –º–æ–¥–µ–ª–∏
    """
    print("–û–±—É—á–µ–Ω–∏–µ –º–æ–¥–µ–ª–∏ –º–∞—à–∏–Ω–Ω–æ–≥–æ –æ–±—É—á–µ–Ω–∏—è –¥–ª—è –ø—Ä–µ–¥–∏–∫—Ç–∏–≤–Ω–æ–π –∞–Ω–∞–ª–∏—Ç–∏–∫–∏ (–±–µ–∑ –≤–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏–∏)")
    print("="*70)
    
    # –°–æ–∑–¥–∞–Ω–∏–µ –ø—Ä–µ–¥–∏–∫—Ç–æ—Ä–∞
    predictor = FetalMLPredictor('f_health.csv')
    
    # –ó–∞–≥—Ä—É–∑–∫–∞ –∏ –ø–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –¥–∞–Ω–Ω—ã—Ö
    X, y = predictor.load_and_prepare_data()
    
    # –†–∞–∑–¥–µ–ª–µ–Ω–∏–µ –Ω–∞ train/test
    predictor.split_data()
    
    # –û–±—É—á–µ–Ω–∏–µ –º–æ–¥–µ–ª–µ–π
    models = predictor.train_models()
    
    # –û—Ü–µ–Ω–∫–∞ –∫–∞—á–µ—Å—Ç–≤–∞
    predictor.evaluate_models()
    
    # –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –ª—É—á—à–µ–π –º–æ–¥–µ–ª–∏
    predictor.save_model()
    
    print("\n–û–±—É—á–µ–Ω–∏–µ –∑–∞–≤–µ—Ä—à–µ–Ω–æ!")
    print("–ú–æ–¥–µ–ª—å –≥–æ—Ç–æ–≤–∞ –¥–ª—è –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è –≤ —Ä–µ–∞–ª—å–Ω–æ–º –≤—Ä–µ–º–µ–Ω–∏")


if __name__ == "__main__":
    main()
