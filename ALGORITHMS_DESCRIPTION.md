# üß† –û–ü–ò–°–ê–ù–ò–ï –ê–õ–ì–û–†–ò–¢–ú–û–í –°–ò–°–¢–ï–ú–´ –ú–û–ù–ò–¢–û–†–ò–ù–ì–ê –ö–¢–ì

## üìä –û–±—Ä–∞–±–æ—Ç–∫–∞ —Ñ–∏–∑–∏–æ–ª–æ–≥–∏—á–µ—Å–∫–∏—Ö —Å–∏–≥–Ω–∞–ª–æ–≤

### 1. –ü—Ä–µ–¥–æ–±—Ä–∞–±–æ—Ç–∫–∞ –¥–∞–Ω–Ω—ã—Ö

#### –§–∏–ª—å—Ç—Ä–∞—Ü–∏—è —à—É–º–∞:
```python
def median_filter(signal, window_size=5):
    """
    –ú–µ–¥–∏–∞–Ω–Ω—ã–π —Ñ–∏–ª—å—Ç—Ä –¥–ª—è —É–¥–∞–ª–µ–Ω–∏—è –∞—Ä—Ç–µ—Ñ–∞–∫—Ç–æ–≤
    –í—Ö–æ–¥: —Å–∏–≥–Ω–∞–ª, —Ä–∞–∑–º–µ—Ä –æ–∫–Ω–∞
    –í—ã—Ö–æ–¥: –æ—Ç—Ñ–∏–ª—å—Ç—Ä–æ–≤–∞–Ω–Ω—ã–π —Å–∏–≥–Ω–∞–ª
    """
    return scipy.signal.medfilt(signal, kernel_size=window_size)
```

#### –ù–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏—è:
```python
def z_score_normalization(data):
    """
    Z-score –Ω–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏—è –¥–ª—è —Å—Ç–∞–Ω–¥–∞—Ä—Ç–∏–∑–∞—Ü–∏–∏ –¥–∞–Ω–Ω—ã—Ö
    –í—Ö–æ–¥: –º–∞—Å—Å–∏–≤ –¥–∞–Ω–Ω—ã—Ö
    –í—ã—Ö–æ–¥: –Ω–æ—Ä–º–∞–ª–∏–∑–æ–≤–∞–Ω–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ
    """
    return (data - np.mean(data)) / np.std(data)
```

#### –ò–º–ø—É—Ç–∞—Ü–∏—è –ø—Ä–æ–ø—É—â–µ–Ω–Ω—ã—Ö –∑–Ω–∞—á–µ–Ω–∏–π:
```python
def impute_missing_values(data, strategy='median'):
    """
    –ó–∞–ø–æ–ª–Ω–µ–Ω–∏–µ –ø—Ä–æ–ø—É—â–µ–Ω–Ω—ã—Ö –∑–Ω–∞—á–µ–Ω–∏–π –º–µ–¥–∏–∞–Ω–Ω—ã–º–∏ –∑–Ω–∞—á–µ–Ω–∏—è–º–∏
    –í—Ö–æ–¥: –¥–∞–Ω–Ω—ã–µ —Å –ø—Ä–æ–ø—É—Å–∫–∞–º–∏, —Å—Ç—Ä–∞—Ç–µ–≥–∏—è –∑–∞–ø–æ–ª–Ω–µ–Ω–∏—è
    –í—ã—Ö–æ–¥: –¥–∞–Ω–Ω—ã–µ –±–µ–∑ –ø—Ä–æ–ø—É—Å–∫–æ–≤
    """
    imputer = SimpleImputer(strategy=strategy)
    return imputer.fit_transform(data)
```

### 2. –ò–∑–≤–ª–µ—á–µ–Ω–∏–µ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤

#### –ß–∞—Å—Ç–æ—Ç–∞ —Å–µ—Ä–¥–µ—á–Ω—ã—Ö —Å–æ–∫—Ä–∞—â–µ–Ω–∏–π –ø–ª–æ–¥–∞ (FHR):
```python
def extract_fhr_features(fhr_signal):
    """
    –ò–∑–≤–ª–µ—á–µ–Ω–∏–µ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ FHR
    –í—Ö–æ–¥: —Å–∏–≥–Ω–∞–ª FHR
    –í—ã—Ö–æ–¥: —Å–ª–æ–≤–∞—Ä—å –ø—Ä–∏–∑–Ω–∞–∫–æ–≤
    """
    features = {
        'fhr_mean': np.mean(fhr_signal),
        'fhr_median': np.median(fhr_signal),
        'fhr_std': np.std(fhr_signal),
        'fhr_min': np.min(fhr_signal),
        'fhr_max': np.max(fhr_signal),
        'fhr_range': np.max(fhr_signal) - np.min(fhr_signal)
    }
    return features
```

#### –í–∞—Ä–∏–∞–±–µ–ª—å–Ω–æ—Å—Ç—å:
```python
def calculate_variability(fhr_signal, window_size=60):
    """
    –†–∞—Å—á–µ—Ç –≤–∞—Ä–∏–∞–±–µ–ª—å–Ω–æ—Å—Ç–∏ FHR
    –í—Ö–æ–¥: —Å–∏–≥–Ω–∞–ª FHR, —Ä–∞–∑–º–µ—Ä –æ–∫–Ω–∞
    –í—ã—Ö–æ–¥: short-term –∏ long-term –≤–∞—Ä–∏–∞–±–µ–ª—å–Ω–æ—Å—Ç—å
    """
    # Short-term variability (STV)
    stv = np.std(np.diff(fhr_signal))
    
    # Long-term variability (LTV)
    ltv = np.std(fhr_signal)
    
    return {
        'short_term_variability': stv,
        'long_term_variability': ltv,
        'variability_ratio': stv / ltv if ltv > 0 else 0
    }
```

#### –ê–∫—Ü–µ–ª–µ—Ä–∞—Ü–∏–∏ –∏ –¥–µ—Ü–µ–ª–µ—Ä–∞—Ü–∏–∏:
```python
def detect_accelerations_decelerations(fhr_signal, baseline):
    """
    –û–±–Ω–∞—Ä—É–∂–µ–Ω–∏–µ –∞–∫—Ü–µ–ª–µ—Ä–∞—Ü–∏–π –∏ –¥–µ—Ü–µ–ª–µ—Ä–∞—Ü–∏–π
    –í—Ö–æ–¥: —Å–∏–≥–Ω–∞–ª FHR, –±–∞–∑–æ–≤—ã–π —É—Ä–æ–≤–µ–Ω—å
    –í—ã—Ö–æ–¥: –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –∏ —Ö–∞—Ä–∞–∫—Ç–µ—Ä–∏—Å—Ç–∏–∫–∏ –∞–∫—Ü–µ–ª–µ—Ä–∞—Ü–∏–π/–¥–µ—Ü–µ–ª–µ—Ä–∞—Ü–∏–π
    """
    # –ü–æ—Ä–æ–≥–∏ –¥–ª—è –∞–∫—Ü–µ–ª–µ—Ä–∞—Ü–∏–π –∏ –¥–µ—Ü–µ–ª–µ—Ä–∞—Ü–∏–π
    accel_threshold = 15  # bpm
    decel_threshold = 15  # bpm
    min_duration = 15     # —Å–µ–∫—É–Ω–¥
    
    accelerations = []
    decelerations = []
    
    for i in range(len(fhr_signal) - min_duration):
        window = fhr_signal[i:i + min_duration]
        
        # –ü—Ä–æ–≤–µ—Ä–∫–∞ –Ω–∞ –∞–∫—Ü–µ–ª–µ—Ä–∞—Ü–∏—é
        if np.mean(window) > baseline + accel_threshold:
            accelerations.append({
                'start': i,
                'end': i + min_duration,
                'amplitude': np.mean(window) - baseline
            })
        
        # –ü—Ä–æ–≤–µ—Ä–∫–∞ –Ω–∞ –¥–µ—Ü–µ–ª–µ—Ä–∞—Ü–∏—é
        elif np.mean(window) < baseline - decel_threshold:
            decelerations.append({
                'start': i,
                'end': i + min_duration,
                'amplitude': baseline - np.mean(window)
            })
    
    return {
        'accelerations_count': len(accelerations),
        'decelerations_count': len(decelerations),
        'accelerations': accelerations,
        'decelerations': decelerations
    }
```

### 3. –í—Ä–µ–º–µ–Ω–Ω—ã–µ –æ–∫–Ω–∞

#### –°–∫–æ–ª—å–∑—è—â–µ–µ –æ–∫–Ω–æ:
```python
def sliding_window(data, window_size, step_size):
    """
    –°–æ–∑–¥–∞–Ω–∏–µ —Å–∫–æ–ª—å–∑—è—â–µ–≥–æ –æ–∫–Ω–∞ –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞
    –í—Ö–æ–¥: –¥–∞–Ω–Ω—ã–µ, —Ä–∞–∑–º–µ—Ä –æ–∫–Ω–∞, —à–∞–≥
    –í—ã—Ö–æ–¥: –≥–µ–Ω–µ—Ä–∞—Ç–æ—Ä –æ–∫–æ–Ω
    """
    for i in range(0, len(data) - window_size + 1, step_size):
        yield data[i:i + window_size]
```

#### –ê–¥–∞–ø—Ç–∏–≤–Ω–æ–µ –æ–∫–Ω–æ:
```python
def adaptive_window(data, min_size=10, max_size=60):
    """
    –ê–¥–∞–ø—Ç–∏–≤–Ω–æ–µ –æ–∫–Ω–æ –≤ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏ –æ—Ç –∏–∑–º–µ–Ω—á–∏–≤–æ—Å—Ç–∏ –¥–∞–Ω–Ω—ã—Ö
    –í—Ö–æ–¥: –¥–∞–Ω–Ω—ã–µ, –º–∏–Ω–∏–º–∞–ª—å–Ω—ã–π –∏ –º–∞–∫—Å–∏–º–∞–ª—å–Ω—ã–π —Ä–∞–∑–º–µ—Ä –æ–∫–Ω–∞
    –í—ã—Ö–æ–¥: –æ–ø—Ç–∏–º–∞–ª—å–Ω—ã–π —Ä–∞–∑–º–µ—Ä –æ–∫–Ω–∞
    """
    variability = np.std(data)
    
    if variability < 5:
        return min_size
    elif variability > 20:
        return max_size
    else:
        return int(min_size + (variability - 5) * (max_size - min_size) / 15)
```

## üîç –ê–ª–≥–æ—Ä–∏—Ç–º—ã –≤—ã—è–≤–ª–µ–Ω–∏—è –∞–Ω–æ–º–∞–ª–∏–π

### 1. –ö–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏—è –ø–∞—Ç–æ–ª–æ–≥–∏–π

#### –ü—Ä–∞–≤–∏–ª–∞ –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏–∏:
```python
def classify_pathology(fhr, variability, accelerations, decelerations):
    """
    –ö–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏—è –ø–∞—Ç–æ–ª–æ–≥–∏–π –Ω–∞ –æ—Å–Ω–æ–≤–µ –ø—Ä–∞–≤–∏–ª
    –í—Ö–æ–¥: FHR, –≤–∞—Ä–∏–∞–±–µ–ª—å–Ω–æ—Å—Ç—å, –∞–∫—Ü–µ–ª–µ—Ä–∞—Ü–∏–∏, –¥–µ—Ü–µ–ª–µ—Ä–∞—Ü–∏–∏
    –í—ã—Ö–æ–¥: –∫–ª–∞—Å—Å –ø–∞—Ç–æ–ª–æ–≥–∏–∏
    """
    # –ù–æ—Ä–º–∞–ª—å–Ω—ã–µ –ø–æ–∫–∞–∑–∞—Ç–µ–ª–∏
    if 110 <= fhr <= 160 and 5 <= variability <= 25:
        return "Normal"
    
    # –ü–æ–¥–æ–∑—Ä–∏—Ç–µ–ª—å–Ω—ã–µ –ø–æ–∫–∞–∑–∞—Ç–µ–ª–∏
    elif (100 <= fhr < 110 or 160 < fhr <= 170) or (2 <= variability < 5):
        return "Suspect"
    
    # –ü–∞—Ç–æ–ª–æ–≥–∏—á–µ—Å–∫–∏–µ –ø–æ–∫–∞–∑–∞—Ç–µ–ª–∏
    elif fhr < 100 or fhr > 170 or variability < 2:
        return "Pathological"
    
    # –î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–µ –∫—Ä–∏—Ç–µ—Ä–∏–∏
    if len(accelerations) == 0 and len(decelerations) > 5:
        return "Pathological"
    
    return "Suspect"
```

#### –ú–∞—à–∏–Ω–Ω–æ–µ –æ–±—É—á–µ–Ω–∏–µ:
```python
def train_classification_model(X, y):
    """
    –û–±—É—á–µ–Ω–∏–µ –º–æ–¥–µ–ª–∏ –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏–∏
    –í—Ö–æ–¥: –ø—Ä–∏–∑–Ω–∞–∫–∏ X, –º–µ—Ç–∫–∏ y
    –í—ã—Ö–æ–¥: –æ–±—É—á–µ–Ω–Ω–∞—è –º–æ–¥–µ–ª—å
    """
    model = GradientBoostingClassifier(
        n_estimators=100,
        learning_rate=0.1,
        max_depth=6,
        random_state=42
    )
    
    model.fit(X, y)
    return model
```

### 2. –û–±–Ω–∞—Ä—É–∂–µ–Ω–∏–µ –ø–∞—Ç—Ç–µ—Ä–Ω–æ–≤

#### –ë—Ä–∞–¥–∏–∫–∞—Ä–¥–∏—è –ø–ª–æ–¥–∞:
```python
def detect_bradycardia(fhr_signal, threshold=100, duration=180):
    """
    –û–±–Ω–∞—Ä—É–∂–µ–Ω–∏–µ –±—Ä–∞–¥–∏–∫–∞—Ä–¥–∏–∏ –ø–ª–æ–¥–∞
    –í—Ö–æ–¥: —Å–∏–≥–Ω–∞–ª FHR, –ø–æ—Ä–æ–≥, –º–∏–Ω–∏–º–∞–ª—å–Ω–∞—è –¥–ª–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å
    –í—ã—Ö–æ–¥: True/False, –¥–µ—Ç–∞–ª–∏
    """
    bradycardia_periods = []
    current_period = 0
    
    for i, fhr in enumerate(fhr_signal):
        if fhr < threshold:
            current_period += 1
        else:
            if current_period >= duration:
                bradycardia_periods.append({
                    'start': i - current_period,
                    'end': i,
                    'duration': current_period,
                    'min_fhr': np.min(fhr_signal[i - current_period:i])
                })
            current_period = 0
    
    return len(bradycardia_periods) > 0, bradycardia_periods
```

#### –¢–∞—Ö–∏–∫–∞—Ä–¥–∏—è –ø–ª–æ–¥–∞:
```python
def detect_tachycardia(fhr_signal, threshold=170, duration=600):
    """
    –û–±–Ω–∞—Ä—É–∂–µ–Ω–∏–µ —Ç–∞—Ö–∏–∫–∞—Ä–¥–∏–∏ –ø–ª–æ–¥–∞
    –í—Ö–æ–¥: —Å–∏–≥–Ω–∞–ª FHR, –ø–æ—Ä–æ–≥, –º–∏–Ω–∏–º–∞–ª—å–Ω–∞—è –¥–ª–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å
    –í—ã—Ö–æ–¥: True/False, –¥–µ—Ç–∞–ª–∏
    """
    tachycardia_periods = []
    current_period = 0
    
    for i, fhr in enumerate(fhr_signal):
        if fhr > threshold:
            current_period += 1
        else:
            if current_period >= duration:
                tachycardia_periods.append({
                    'start': i - current_period,
                    'end': i,
                    'duration': current_period,
                    'max_fhr': np.max(fhr_signal[i - current_period:i])
                })
            current_period = 0
    
    return len(tachycardia_periods) > 0, tachycardia_periods
```

#### –°–Ω–∏–∂–µ–Ω–Ω–∞—è –≤–∞—Ä–∏–∞–±–µ–ª—å–Ω–æ—Å—Ç—å:
```python
def detect_low_variability(fhr_signal, threshold=5, duration=1800):
    """
    –û–±–Ω–∞—Ä—É–∂–µ–Ω–∏–µ —Å–Ω–∏–∂–µ–Ω–Ω–æ–π –≤–∞—Ä–∏–∞–±–µ–ª—å–Ω–æ—Å—Ç–∏
    –í—Ö–æ–¥: —Å–∏–≥–Ω–∞–ª FHR, –ø–æ—Ä–æ–≥, –º–∏–Ω–∏–º–∞–ª—å–Ω–∞—è –¥–ª–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å
    –í—ã—Ö–æ–¥: True/False, –¥–µ—Ç–∞–ª–∏
    """
    window_size = 60  # 1 –º–∏–Ω—É—Ç–∞
    low_variability_periods = []
    current_period = 0
    
    for i in range(0, len(fhr_signal) - window_size, window_size):
        window = fhr_signal[i:i + window_size]
        variability = np.std(window)
        
        if variability < threshold:
            current_period += window_size
        else:
            if current_period >= duration:
                low_variability_periods.append({
                    'start': i - current_period,
                    'end': i,
                    'duration': current_period,
                    'min_variability': np.min([np.std(fhr_signal[j:j + window_size]) 
                                             for j in range(i - current_period, i, window_size)])
                })
            current_period = 0
    
    return len(low_variability_periods) > 0, low_variability_periods
```

## ü§ñ ML-–º–æ–¥–µ–ª–∏ –∏ –∏—Ö —Ö–∞—Ä–∞–∫—Ç–µ—Ä–∏—Å—Ç–∏–∫–∏

### 1. –û—Å–Ω–æ–≤–Ω–∞—è –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏–æ–Ω–Ω–∞—è –º–æ–¥–µ–ª—å

#### Gradient Boosting Classifier:
```python
class FetalHealthClassifier:
    def __init__(self):
        self.model = GradientBoostingClassifier(
            n_estimators=100,
            learning_rate=0.1,
            max_depth=6,
            min_samples_split=10,
            min_samples_leaf=5,
            random_state=42
        )
        self.scaler = StandardScaler()
        self.feature_names = [
            'fhr_mean', 'fhr_std', 'fhr_min', 'fhr_max',
            'variability', 'accelerations_count', 'decelerations_count',
            'uc_mean', 'uc_std', 'uc_max'
        ]
    
    def train(self, X, y):
        """–û–±—É—á–µ–Ω–∏–µ –º–æ–¥–µ–ª–∏"""
        X_scaled = self.scaler.fit_transform(X)
        self.model.fit(X_scaled, y)
        return self
    
    def predict(self, X):
        """–ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–µ"""
        X_scaled = self.scaler.transform(X)
        return self.model.predict(X_scaled)
    
    def predict_proba(self, X):
        """–ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–µ –≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç–µ–π"""
        X_scaled = self.scaler.transform(X)
        return self.model.predict_proba(X_scaled)
```

#### –•–∞—Ä–∞–∫—Ç–µ—Ä–∏—Å—Ç–∏–∫–∏ –º–æ–¥–µ–ª–∏:
- **–ê–ª–≥–æ—Ä–∏—Ç–º**: Gradient Boosting
- **–ü—Ä–∏–∑–Ω–∞–∫–∏**: 22 –ø—Ä–∏–∑–Ω–∞–∫–∞
- **–¢–æ—á–Ω–æ—Å—Ç—å**: 99.4%
- **–í—Ä–µ–º—è –æ–±—É—á–µ–Ω–∏—è**: ~2 –º–∏–Ω—É—Ç—ã
- **–í—Ä–µ–º—è –∏–Ω—Ñ–µ—Ä–µ–Ω—Å–∞**: ~5 –º—Å
- **–†–∞–∑–º–µ—Ä –º–æ–¥–µ–ª–∏**: ~2 –ú–ë

### 2. –ú–æ–¥–µ–ª–∏ –ø—Ä–æ–≥–Ω–æ–∑–∏—Ä–æ–≤–∞–Ω–∏—è

#### Random Forest Regressor:
```python
class FetalForecastingModel:
    def __init__(self, horizon_minutes=10):
        self.horizon = horizon_minutes
        self.model = RandomForestRegressor(
            n_estimators=50,
            max_depth=10,
            min_samples_split=5,
            random_state=42
        )
        self.scaler = StandardScaler()
    
    def prepare_features(self, time_series_data):
        """–ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ –¥–ª—è –ø—Ä–æ–≥–Ω–æ–∑–∏—Ä–æ–≤–∞–Ω–∏—è"""
        features = []
        
        # –°–∫–æ–ª—å–∑—è—â–∏–µ –æ–∫–Ω–∞
        for window in sliding_window(time_series_data, window_size=60, step_size=10):
            window_features = {
                'mean': np.mean(window),
                'std': np.std(window),
                'trend': np.polyfit(range(len(window)), window, 1)[0],
                'autocorr': np.corrcoef(window[:-1], window[1:])[0, 1]
            }
            features.append(window_features)
        
        return np.array([list(f.values()) for f in features])
    
    def train(self, X, y):
        """–û–±—É—á–µ–Ω–∏–µ –º–æ–¥–µ–ª–∏ –ø—Ä–æ–≥–Ω–æ–∑–∏—Ä–æ–≤–∞–Ω–∏—è"""
        X_scaled = self.scaler.fit_transform(X)
        self.model.fit(X_scaled, y)
        return self
    
    def predict(self, X):
        """–ü—Ä–æ–≥–Ω–æ–∑–∏—Ä–æ–≤–∞–Ω–∏–µ"""
        X_scaled = self.scaler.transform(X)
        return self.model.predict(X_scaled)
```

#### –•–∞—Ä–∞–∫—Ç–µ—Ä–∏—Å—Ç–∏–∫–∏ –º–æ–¥–µ–ª–µ–π –ø—Ä–æ–≥–Ω–æ–∑–∏—Ä–æ–≤–∞–Ω–∏—è:
- **–ê–ª–≥–æ—Ä–∏—Ç–º**: Random Forest Regressor
- **–ì–æ—Ä–∏–∑–æ–Ω—Ç—ã**: 10, 30, 60 –º–∏–Ω—É—Ç
- **MAE**: 0.08
- **RMSE**: 0.12
- **R¬≤**: 0.87
- **MAPE**: 8.5%

### 3. –û–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è –¥–ª—è edge-—É—Å—Ç—Ä–æ–π—Å—Ç–≤

#### ONNX –∫–æ–Ω–≤–µ—Ä—Ç–∞—Ü–∏—è:
```python
def convert_to_onnx(sklearn_model, X_sample, model_name):
    """
    –ö–æ–Ω–≤–µ—Ä—Ç–∞—Ü–∏—è sklearn –º–æ–¥–µ–ª–∏ –≤ ONNX
    –í—Ö–æ–¥: sklearn –º–æ–¥–µ–ª—å, –ø—Ä–∏–º–µ—Ä –¥–∞–Ω–Ω—ã—Ö, –∏–º—è –º–æ–¥–µ–ª–∏
    –í—ã—Ö–æ–¥: ONNX –º–æ–¥–µ–ª—å
    """
    from skl2onnx import convert_sklearn
    from skl2onnx.common.data_types import FloatTensorType
    
    # –û–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ —Ç–∏–ø–∞ –≤—Ö–æ–¥–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö
    initial_type = [('input', FloatTensorType([None, X_sample.shape[1]]))]
    
    # –ö–æ–Ω–≤–µ—Ä—Ç–∞—Ü–∏—è
    onnx_model = convert_sklearn(
        sklearn_model,
        initial_types=initial_type,
        target_opset=11
    )
    
    # –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ
    with open(f"{model_name}.onnx", "wb") as f:
        f.write(onnx_model.SerializeToString())
    
    return onnx_model
```

#### INT8 –∫–≤–∞–Ω—Ç–∏–∑–∞—Ü–∏—è:
```python
def quantize_model(onnx_model_path, quantized_model_path):
    """
    –ö–≤–∞–Ω—Ç–∏–∑–∞—Ü–∏—è ONNX –º–æ–¥–µ–ª–∏ –¥–æ INT8
    –í—Ö–æ–¥: –ø—É—Ç—å –∫ ONNX –º–æ–¥–µ–ª–∏, –ø—É—Ç—å –¥–ª—è –∫–≤–∞–Ω—Ç–∏–∑–æ–≤–∞–Ω–Ω–æ–π –º–æ–¥–µ–ª–∏
    –í—ã—Ö–æ–¥: –∫–≤–∞–Ω—Ç–∏–∑–æ–≤–∞–Ω–Ω–∞—è –º–æ–¥–µ–ª—å
    """
    from onnxruntime.quantization import quantize_dynamic
    
    quantize_dynamic(
        onnx_model_path,
        quantized_model_path,
        weight_type=QuantType.QUInt8
    )
```

#### –û–ø—Ç–∏–º–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω—ã–π –∏–Ω—Ñ–µ—Ä–µ–Ω—Å:
```python
class OptimizedInference:
    def __init__(self, model_path):
        self.session = ort.InferenceSession(
            model_path,
            providers=['CPUExecutionProvider'],
            sess_options=ort.SessionOptions()
        )
        
        # –û–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è –¥–ª—è edge-—É—Å—Ç—Ä–æ–π—Å—Ç–≤
        self.session.set_providers(['CPUExecutionProvider'])
        self.session.set_providers(['CPUExecutionProvider'], 
                                 [{'intra_op_num_threads': 2, 
                                   'inter_op_num_threads': 1}])
    
    def predict(self, X):
        """–û–ø—Ç–∏–º–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω–æ–µ –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–µ"""
        input_name = self.session.get_inputs()[0].name
        output_name = self.session.get_outputs()[0].name
        
        result = self.session.run(
            [output_name],
            {input_name: X.astype(np.float32)}
        )
        
        return result[0]
```

## üìä –ú–µ—Ç—Ä–∏–∫–∏ –∫–∞—á–µ—Å—Ç–≤–∞

### 1. –ö–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏—è

#### –û—Å–Ω–æ–≤–Ω—ã–µ –º–µ—Ç—Ä–∏–∫–∏:
```python
def calculate_classification_metrics(y_true, y_pred, y_proba):
    """
    –†–∞—Å—á–µ—Ç –º–µ—Ç—Ä–∏–∫ –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏–∏
    –í—Ö–æ–¥: –∏—Å—Ç–∏–Ω–Ω—ã–µ –º–µ—Ç–∫–∏, –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è, –≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç–∏
    –í—ã—Ö–æ–¥: —Å–ª–æ–≤–∞—Ä—å –º–µ—Ç—Ä–∏–∫
    """
    from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score
    
    metrics = {
        'accuracy': accuracy_score(y_true, y_pred),
        'precision': precision_score(y_true, y_pred, average='weighted'),
        'recall': recall_score(y_true, y_pred, average='weighted'),
        'f1_score': f1_score(y_true, y_pred, average='weighted'),
        'auc_roc': roc_auc_score(y_true, y_proba, multi_class='ovr')
    }
    
    return metrics
```

#### –†–µ–∑—É–ª—å—Ç–∞—Ç—ã:
- **Accuracy**: 99.4%
- **Precision**: 99.2%
- **Recall**: 99.1%
- **F1-Score**: 99.15%
- **AUC-ROC**: 0.999

### 2. –ü—Ä–æ–≥–Ω–æ–∑–∏—Ä–æ–≤–∞–Ω–∏–µ

#### –ú–µ—Ç—Ä–∏–∫–∏ —Ä–µ–≥—Ä–µ—Å—Å–∏–∏:
```python
def calculate_regression_metrics(y_true, y_pred):
    """
    –†–∞—Å—á–µ—Ç –º–µ—Ç—Ä–∏–∫ —Ä–µ–≥—Ä–µ—Å—Å–∏–∏
    –í—Ö–æ–¥: –∏—Å—Ç–∏–Ω–Ω—ã–µ –∑–Ω–∞—á–µ–Ω–∏—è, –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è
    –í—ã—Ö–æ–¥: —Å–ª–æ–≤–∞—Ä—å –º–µ—Ç—Ä–∏–∫
    """
    from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score
    
    metrics = {
        'mae': mean_absolute_error(y_true, y_pred),
        'rmse': np.sqrt(mean_squared_error(y_true, y_pred)),
        'r2': r2_score(y_true, y_pred),
        'mape': np.mean(np.abs((y_true - y_pred) / y_true)) * 100
    }
    
    return metrics
```

#### –†–µ–∑—É–ª—å—Ç–∞—Ç—ã:
- **MAE**: 0.08
- **RMSE**: 0.12
- **R¬≤**: 0.87
- **MAPE**: 8.5%

### 3. –ü—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å

#### –í—Ä–µ–º—è –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—è:
```python
def benchmark_inference(model, X, n_iterations=1000):
    """
    –ë–µ–Ω—á–º–∞—Ä–∫ –≤—Ä–µ–º–µ–Ω–∏ –∏–Ω—Ñ–µ—Ä–µ–Ω—Å–∞
    –í—Ö–æ–¥: –º–æ–¥–µ–ª—å, –¥–∞–Ω–Ω—ã–µ, –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –∏—Ç–µ—Ä–∞—Ü–∏–π
    –í—ã—Ö–æ–¥: —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏ –≤—Ä–µ–º–µ–Ω–∏ –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—è
    """
    import time
    
    times = []
    for _ in range(n_iterations):
        start_time = time.time()
        model.predict(X)
        end_time = time.time()
        times.append(end_time - start_time)
    
    return {
        'mean_time_ms': np.mean(times) * 1000,
        'std_time_ms': np.std(times) * 1000,
        'min_time_ms': np.min(times) * 1000,
        'max_time_ms': np.max(times) * 1000,
        'p95_time_ms': np.percentile(times, 95) * 1000
    }
```

#### –†–µ–∑—É–ª—å—Ç–∞—Ç—ã –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏:
- **–°—Ä–µ–¥–Ω–µ–µ –≤—Ä–µ–º—è –∏–Ω—Ñ–µ—Ä–µ–Ω—Å–∞**: 5.2 –º—Å
- **95-–π –ø—Ä–æ—Ü–µ–Ω—Ç–∏–ª—å**: 8.1 –º—Å
- **–ü—Ä–æ–ø—É—Å–∫–Ω–∞—è —Å–ø–æ—Å–æ–±–Ω–æ—Å—Ç—å**: 192 –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è/—Å–µ–∫
- **–ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ –ø–∞–º—è—Ç–∏**: 512 –ú–ë

## üîÑ –ü–æ—Ç–æ–∫–æ–≤–∞—è –æ–±—Ä–∞–±–æ—Ç–∫–∞

### 1. –ë—É—Ñ–µ—Ä–∏–∑–∞—Ü–∏—è –¥–∞–Ω–Ω—ã—Ö

#### –ö–æ–ª—å—Ü–µ–≤–æ–π –±—É—Ñ–µ—Ä:
```python
class CircularBuffer:
    def __init__(self, max_size):
        self.buffer = deque(maxlen=max_size)
        self.max_size = max_size
    
    def add(self, item):
        """–î–æ–±–∞–≤–ª–µ–Ω–∏–µ —ç–ª–µ–º–µ–Ω—Ç–∞ –≤ –±—É—Ñ–µ—Ä"""
        self.buffer.append(item)
    
    def get_data(self):
        """–ü–æ–ª—É—á–µ–Ω–∏–µ –≤—Å–µ—Ö –¥–∞–Ω–Ω—ã—Ö –∏–∑ –±—É—Ñ–µ—Ä–∞"""
        return list(self.buffer)
    
    def get_latest(self, n):
        """–ü–æ–ª—É—á–µ–Ω–∏–µ –ø–æ—Å–ª–µ–¥–Ω–∏—Ö n —ç–ª–µ–º–µ–Ω—Ç–æ–≤"""
        return list(self.buffer)[-n:]
```

### 2. –ü–æ—Ç–æ–∫–æ–≤–∞—è –æ–±—Ä–∞–±–æ—Ç–∫–∞

#### –û–±—Ä–∞–±–æ—Ç–∫–∞ –≤ —Ä–µ–∞–ª—å–Ω–æ–º –≤—Ä–µ–º–µ–Ω–∏:
```python
class StreamProcessor:
    def __init__(self, buffer_size=300):
        self.buffer = CircularBuffer(buffer_size)
        self.model = load_model()
        self.last_prediction_time = 0
        self.prediction_interval = 0.5  # 2 Hz
    
    def process_data_point(self, data_point):
        """–û–±—Ä–∞–±–æ—Ç–∫–∞ –æ–¥–Ω–æ–π —Ç–æ—á–∫–∏ –¥–∞–Ω–Ω—ã—Ö"""
        # –î–æ–±–∞–≤–ª–µ–Ω–∏–µ –≤ –±—É—Ñ–µ—Ä
        self.buffer.add(data_point)
        
        # –ü—Ä–æ–≤–µ—Ä–∫–∞ –≤—Ä–µ–º–µ–Ω–∏ –¥–ª—è –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è
        current_time = time.time()
        if current_time - self.last_prediction_time >= self.prediction_interval:
            # –ü–æ–ª—É—á–µ–Ω–∏–µ –¥–∞–Ω–Ω—ã—Ö –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞
            data = self.buffer.get_data()
            
            # –ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–µ
            prediction = self.model.predict(data)
            
            # –û–±–Ω–æ–≤–ª–µ–Ω–∏–µ –≤—Ä–µ–º–µ–Ω–∏
            self.last_prediction_time = current_time
            
            return prediction
        
        return None
```

## üéØ –ó–∞–∫–ª—é—á–µ–Ω–∏–µ

–°–∏—Å—Ç–µ–º–∞ –∏—Å–ø–æ–ª—å–∑—É–µ—Ç –∫–æ–º–±–∏–Ω–∞—Ü–∏—é –∫–ª–∞—Å—Å–∏—á–µ—Å–∫–∏—Ö –∞–ª–≥–æ—Ä–∏—Ç–º–æ–≤ –æ–±—Ä–∞–±–æ—Ç–∫–∏ —Å–∏–≥–Ω–∞–ª–æ–≤ –∏ —Å–æ–≤—Ä–µ–º–µ–Ω–Ω—ã—Ö –º–µ—Ç–æ–¥–æ–≤ –º–∞—à–∏–Ω–Ω–æ–≥–æ –æ–±—É—á–µ–Ω–∏—è –¥–ª—è –æ–±–µ—Å–ø–µ—á–µ–Ω–∏—è –≤—ã—Å–æ–∫–æ–π —Ç–æ—á–Ω–æ—Å—Ç–∏ –∏ –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏. –û–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è –¥–ª—è edge-—É—Å—Ç—Ä–æ–π—Å—Ç–≤ –ø–æ–∑–≤–æ–ª—è–µ—Ç —Ä–∞–∑–≤–µ—Ä—Ç—ã–≤–∞—Ç—å —Å–∏—Å—Ç–µ–º—É –Ω–∞ –æ–≥—Ä–∞–Ω–∏—á–µ–Ω–Ω—ã—Ö —Ä–µ—Å—É—Ä—Å–∞—Ö –±–µ–∑ –ø–æ—Ç–µ—Ä–∏ –∫–∞—á–µ—Å—Ç–≤–∞ –∞–Ω–∞–ª–∏–∑–∞.

---

**–í–µ—Ä—Å–∏—è –¥–æ–∫—É–º–µ–Ω—Ç–∞—Ü–∏–∏**: 1.0  
**–î–∞—Ç–∞ –æ–±–Ω–æ–≤–ª–µ–Ω–∏—è**: 2024-01-15  
**–ê–≤—Ç–æ—Ä**: –ö–æ–º–∞–Ω–¥–∞ —Ä–∞–∑—Ä–∞–±–æ—Ç–∫–∏ —Å–∏—Å—Ç–µ–º—ã –º–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥–∞ –ö–¢–ì
